{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "##helper libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from subprocess import check_output\n",
    "from collections import Counter\n",
    "import gc\n",
    "#keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, SpatialDropout1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#model export\n",
    "import time\n",
    "from keras import metrics\n",
    "import h5py\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "dat = pd.read_csv('D:\\\\Azim\\\\CNN\\\\train.txt',sep='\\t',header=None,encoding='latin')\n",
    "tags = dat[0].str[2:7]+dat[0].str[9]\n",
    "texts = dat[0].str.replace(pat='__label__2',n=1,repl='')\n",
    "texts = dat[0].str.replace(pat='__label__1',n=1,repl='')\n",
    "\n",
    "#free memory\n",
    "del dat\n",
    "gc.collect()\n",
    "dat=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_max = 1000\n",
    "tok = Tokenizer(num_words=num_max)\n",
    "tok.fit_on_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23, 16, 74, 11, 1, 615, 8, 176, 490, 13, 367, 6, 1, 10, 60, 442, 28, 69, 3, 40, 6, 74, 5, 135, 72, 684, 145, 119, 3, 21, 529, 1, 145, 17, 41, 7, 29, 7, 1, 601, 3, 21, 132, 529, 6, 45, 1, 88, 119, 6, 242, 38, 2, 427, 4, 863, 18, 2, 6, 40, 208, 72, 5, 339]\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  23  16  74  11   1 615   8 176 490  13 367   6   1  10  60 442  28  69\n",
      "   3  40   6  74   5 135  72 684 145 119   3  21 529   1 145  17  41   7\n",
      "  29   7   1 601   3  21 132 529   6  45   1  88 119   6 242  38   2 427\n",
      "   4 863  18   2   6  40 208  72   5 339]\n",
      "(3600000, 100)\n"
     ]
    }
   ],
   "source": [
    "# preprocess\n",
    "le = LabelEncoder()\n",
    "tags = le.fit_transform(tags)\n",
    "\n",
    "# for cnn preproces\n",
    "max_len = 100\n",
    "cnn_texts_seq = tok.texts_to_sequences(texts)\n",
    "print(cnn_texts_seq[0])\n",
    "cnn_texts_mat = sequence.pad_sequences(cnn_texts_seq,maxlen=max_len)\n",
    "print(cnn_texts_mat[0])\n",
    "print(cnn_texts_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding\n",
    "max_features = 20000\n",
    "maxlen = 100\n",
    "embedding_size = 128\n",
    "\n",
    "# Convolution\n",
    "kernel_size = 5\n",
    "filters = 64\n",
    "pool_size = 4\n",
    "\n",
    "# LSTM\n",
    "lstm_output_size = 70\n",
    "\n",
    "# Training\n",
    "batch_size = 30\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_size, input_length=maxlen))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Conv1D(filters,\n",
    "#                 kernel_size,\n",
    "#                 padding='valid',\n",
    "#                 activation='relu',\n",
    "#                 strides=1))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(Bidirectional(LSTM(256, dropout=0.2)))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2880000 samples, validate on 720000 samples\n",
      "Epoch 1/3\n",
      "2880000/2880000 [==============================] - 62896s 22ms/step - loss: 0.0579 - acc: 0.9748 - val_loss: 0.0461 - val_acc: 0.9808\n",
      "Epoch 2/3\n",
      "2880000/2880000 [==============================] - 62227s 22ms/step - loss: 0.0470 - acc: 0.9802 - val_loss: 0.0425 - val_acc: 0.9825\n",
      "Epoch 3/3\n",
      "2880000/2880000 [==============================] - 61540s 21ms/step - loss: 0.0464 - acc: 0.9806 - val_loss: 0.0425 - val_acc: 0.9823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xddb53e4780>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(cnn_texts_mat,tags,batch_size=32,epochs=3,verbose=1,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "dat = pd.read_csv('D:\\\\Azim\\\\CNN\\\\test.txt',sep='\\t',header=None,encoding='latin')\n",
    "test_tags = dat[0].str[2:7]+dat[0].str[9]\n",
    "test_texts = dat[0].str.replace(pat='__label__2',n=1,repl='')\n",
    "test_texts = dat[0].str.replace(pat='__label__1',n=1,repl='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#free memory\n",
    "del dat\n",
    "gc.collect()\n",
    "dat=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_max = 1000\n",
    "test_tok = Tokenizer(num_words=num_max)\n",
    "test_tok.fit_on_texts(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23, 16, 31, 94, 21, 45, 26, 7, 1, 31, 7, 79, 3, 22, 5, 8, 94, 11, 137, 2, 3, 127, 81, 6, 52, 110, 10, 4, 33, 6, 210, 44, 233, 91, 4, 128, 38, 34, 10, 1, 8, 94, 38, 154, 25, 2, 651, 38, 26, 7, 8, 9, 4, 94, 10, 21, 20, 180, 97, 124, 129, 6, 224, 9, 38, 871, 44, 3, 239, 8, 53, 619, 425, 581, 467, 134, 512, 26, 163, 72, 13, 12, 925]\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  23\n",
      "  16  31  94  21  45  26   7   1  31   7  79   3  22   5   8  94  11 137\n",
      "   2   3 127  81   6  52 110  10   4  33   6 210  44 233  91   4 128  38\n",
      "  34  10   1   8  94  38 154  25   2 651  38  26   7   8   9   4  94  10\n",
      "  21  20 180  97 124 129   6 224   9  38 871  44   3 239   8  53 619 425\n",
      " 581 467 134 512  26 163  72  13  12 925]\n",
      "(400000, 100)\n"
     ]
    }
   ],
   "source": [
    "# for cnn preproces\n",
    "max_len = 100\n",
    "test_cnn_texts_seq = test_tok.texts_to_sequences(test_texts)\n",
    "print(test_cnn_texts_seq[0])\n",
    "test_cnn_texts_mat = sequence.pad_sequences(test_cnn_texts_seq,maxlen=max_len)\n",
    "print(test_cnn_texts_mat[0])\n",
    "print(test_cnn_texts_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess\n",
    "le = LabelEncoder()\n",
    "test_tags = le.fit_transform(test_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400000,)\n"
     ]
    }
   ],
   "source": [
    "print(test_tags.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000/400000 [==============================] - 2655s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_cnn_texts_mat,test_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on test data is 94.84825000000001 percent\n"
     ]
    }
   ],
   "source": [
    "print(\"Model accuracy on test data is\",scores[1]*100,\"percent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_backup=model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"D:\\\\Azim\\\\LSTM_Bidirectional\\\\model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#import cythonmagic\n",
    "model.save_weights(\"D:\\\\Azim\\\\LSTM_Bidirectional\\\\model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
